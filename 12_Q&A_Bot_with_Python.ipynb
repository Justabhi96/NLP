{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - 12. Q&A Bot with Python",
      "provenance": [],
      "authorship_tag": "ABX9TyM88ehfUyWjKWSXWIj10K6W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Justabhi96/NLP/blob/master/12_Q%26A_Bot_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRL3jA855xau",
        "colab_type": "text"
      },
      "source": [
        "## Link to the paper --> https://arxiv.org/pdf/1503.08895.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEWRiaDw2Ek_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQLLriPK2hLM",
        "colab_type": "code",
        "outputId": "e3387024-a50b-4f7f-9971-bc09220817ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with open(\"train_qa.txt\", \"rb\") as f:\n",
        "  train_data = pickle.load(f)\n",
        "with open(\"test_qa.txt\", \"rb\") as f:\n",
        "  test_data = pickle.load(f)\n",
        "\n",
        "len(train_data), len(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YWbTFJT3UnD",
        "colab_type": "code",
        "outputId": "b73cd07a-77f7-40b5-d67f-7572b9cc0efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlEKWKV43_vu",
        "colab_type": "text"
      },
      "source": [
        "###Create a Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weCNM7Ft36Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = train_data + test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wYYPm7I3-yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for story, question, ans in all_data:\n",
        "  vocab = vocab.union(set(story))\n",
        "  vocab = vocab.union(set(question))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzjsu6Bq4iLT",
        "colab_type": "code",
        "outputId": "1985b6d0-1488-4478-82aa-b9ce17f86e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab.add(\"no\")\n",
        "vocab.add(\"yes\")\n",
        "\n",
        "vocab_len = len(vocab)+1 # for keras pad sequence to have a placeholder\n",
        "vocab_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHf8FBnM48Ya",
        "colab_type": "code",
        "outputId": "3c374d78-d973-4fe7-f406-265cb18e70c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# longest story\n",
        "all_story_lens = [len(data[0]) for data in all_data]\n",
        "max_story_len = max(all_story_lens)\n",
        "max_story_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2h7_Z2e5ax9",
        "colab_type": "code",
        "outputId": "c4573519-368f-43a1-c809-586b18f7475a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# longest question\n",
        "all_que_lens = [len(data[1]) for data in all_data]\n",
        "max_que_len = max(all_que_lens)\n",
        "max_que_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTMtW4tO6G1u",
        "colab_type": "text"
      },
      "source": [
        "###Vectorize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVi8EF_5lPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwEI_FBE6rAh",
        "colab_type": "code",
        "outputId": "1472017f-b507-488e-d23f-ae95d639b2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "source": [
        "tokenizer = Tokenizer(filters = [])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 36,\n",
              " '?': 37,\n",
              " 'apple': 32,\n",
              " 'back': 22,\n",
              " 'bathroom': 10,\n",
              " 'bedroom': 15,\n",
              " 'daniel': 26,\n",
              " 'discarded': 4,\n",
              " 'down': 23,\n",
              " 'dropped': 19,\n",
              " 'football': 18,\n",
              " 'garden': 31,\n",
              " 'got': 8,\n",
              " 'grabbed': 29,\n",
              " 'hallway': 5,\n",
              " 'in': 9,\n",
              " 'is': 25,\n",
              " 'john': 2,\n",
              " 'journeyed': 11,\n",
              " 'kitchen': 17,\n",
              " 'left': 24,\n",
              " 'mary': 33,\n",
              " 'milk': 28,\n",
              " 'moved': 3,\n",
              " 'no': 12,\n",
              " 'office': 13,\n",
              " 'picked': 30,\n",
              " 'put': 7,\n",
              " 'sandra': 14,\n",
              " 'the': 35,\n",
              " 'there': 27,\n",
              " 'to': 20,\n",
              " 'took': 21,\n",
              " 'travelled': 1,\n",
              " 'up': 6,\n",
              " 'went': 34,\n",
              " 'yes': 16}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glKqJglS63CR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index = tokenizer.word_index, max_story_len = max_story_len, \n",
        "                      max_que_len = max_que_len):\n",
        "  # stories\n",
        "  X = []\n",
        "  # questions\n",
        "  Xq = []\n",
        "  # answers\n",
        "  Y = []\n",
        "\n",
        "  for story, que, ans in data:\n",
        "    x = [word_index[word.lower()] for word in story]\n",
        "    xq = [word_index[word.lower()] for word in que]\n",
        "\n",
        "    y = np.zeros(len(word_index)+1)\n",
        "    y[word_index[ans]] = 1\n",
        "\n",
        "    X.append(x)\n",
        "    Xq.append(xq)\n",
        "    Y.append(y)\n",
        "\n",
        "  return (pad_sequences(X, maxlen = max_story_len),\n",
        "          pad_sequences(Xq, maxlen = max_que_len),\n",
        "          np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMNmts1-940m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_story_train, inputs_que_train, inputs_ans_train = vectorize_stories(train_data)\n",
        "inputs_story_test, inputs_que_test, inputs_ans_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7CD3Ld-3b0",
        "colab_type": "code",
        "outputId": "5a5338d1-076b-4d38-ec17-55c863050f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "inputs_story_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 35, 15, 36],\n",
              "       [ 0,  0,  0, ..., 35,  5, 36],\n",
              "       [ 0,  0,  0, ..., 35, 10, 36],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 35, 15, 36],\n",
              "       [ 0,  0,  0, ..., 28, 27, 36],\n",
              "       [ 0,  0,  0, ..., 32, 27, 36]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W0-HIQg-78h",
        "colab_type": "text"
      },
      "source": [
        "###Build Network\n",
        "  1. Input Encoder M\n",
        "  2. Input Encoder C\n",
        "  3. Question Encoder\n",
        "\n",
        "####Complete the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09gyfE6R-4VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiSqiNBRAFI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# placeholder shape = (max_story_len, batch_size)\n",
        "\n",
        "input_seq = Input((max_story_len,))\n",
        "question = Input((max_que_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qLr_dQKDI9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = vocab_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvSlwHbhDNkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim = vocab_size, output_dim = 64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# OUTPUT --> (samples, story_max_len, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WecXs4t5EOfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim = vocab_size, output_dim = max_que_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "\n",
        "# OUTPUT --> (samples, story_max_len, max_que_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dioUCNTeEY0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim = vocab_size, output_dim = 64, input_length = max_que_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "\n",
        "# OUTPUT --> (samples, max_que_len, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGuEqvtAE1HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoded --> encoder(input)\n",
        "input_encoded_m = input_encoder_m(input_seq)\n",
        "input_encoded_c = input_encoder_c(input_seq)\n",
        "\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2nrIZsF9XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = dot([input_encoded_m, question_encoded], axes = (2,2))\n",
        "match = Activation(\"softmax\")(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc5sO0zTGN7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = add([match, input_encoded_c])\n",
        "response = Permute((2,1))(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyFG480yGbvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8274dcc5-618a-4134-b3ed-f865e1aa462a"
      },
      "source": [
        "answer = concatenate([response, question_encoded])\n",
        "answer"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsdLgyD7Gj2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = LSTM(32)(answer)\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation(\"softmax\")(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlw2LLJeHC4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "2b936d72-e4dc-43ce-c06a-0933a93344c0"
      },
      "source": [
        "model = Model([input_seq, question], answer)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer= \"rmsprop\", metrics = [\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       multiple             2432        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_6 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 156, 6)       0           sequential_3[1][0]               \n",
            "                                                                 sequential_6[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       multiple             228         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
            "                                                                 sequential_4[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_6[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOy5RM5cHXq_",
        "colab_type": "text"
      },
      "source": [
        "###Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0J867xwHUBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "dffaae5d-d499-4812-a866-23cdf36c7458"
      },
      "source": [
        "# I ran this code 3 times that's why accuracy is good on first epoch itself\n",
        "# accuracy is as good as running with 30 epochs\n",
        "r = model.fit([inputs_story_train, inputs_que_train], inputs_ans_train, batch_size = 32, epochs = 10,\n",
        "              validation_data = ([inputs_story_test, inputs_que_test], inputs_ans_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 7s 718us/step - loss: 0.4992 - acc: 0.7552 - val_loss: 0.5042 - val_acc: 0.7450\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 7s 718us/step - loss: 0.4965 - acc: 0.7596 - val_loss: 0.5014 - val_acc: 0.7550\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 7s 721us/step - loss: 0.4750 - acc: 0.7745 - val_loss: 0.4798 - val_acc: 0.7710\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 7s 718us/step - loss: 0.4679 - acc: 0.7774 - val_loss: 0.4669 - val_acc: 0.7890\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 7s 719us/step - loss: 0.4492 - acc: 0.7933 - val_loss: 0.4409 - val_acc: 0.7950\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 7s 712us/step - loss: 0.4339 - acc: 0.8012 - val_loss: 0.4344 - val_acc: 0.8090\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 7s 721us/step - loss: 0.4137 - acc: 0.8165 - val_loss: 0.4059 - val_acc: 0.8160\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 7s 722us/step - loss: 0.4026 - acc: 0.8204 - val_loss: 0.4511 - val_acc: 0.7870\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 7s 721us/step - loss: 0.3891 - acc: 0.8295 - val_loss: 0.3949 - val_acc: 0.8190\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 7s 716us/step - loss: 0.3819 - acc: 0.8347 - val_loss: 0.3920 - val_acc: 0.8210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6eA3QKBH-Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"my_chatbot_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh7qbS0TLsh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def predict_on_random_test_data():\n",
        "  random_index = random.randint(0, len(inputs_story_test))\n",
        "\n",
        "  story = inputs_story_test[random_index]\n",
        "  que = inputs_que_test[random_index]\n",
        "  print(\"====================== Story ============================\\n\")\n",
        "  print(\" \".join([tokenizer.index_word.get(val) for val in list(story) if val > 0]))\n",
        "  print(\"\\n====================== Question ============================\\n\")\n",
        "  print(\" \".join([tokenizer.index_word.get(val) for val in list(que) if val > 0]))\n",
        "  print(\"\\n==================== Answer ==============================\\n\")\n",
        "  sample_data = [[story], [que]]\n",
        "\n",
        "  pred_data = model.predict((sample_data))\n",
        "  pred_index = np.argmax(pred_data[0])\n",
        "  for key, val in tokenizer.word_index.items():\n",
        "    if val == pred_index:\n",
        "      print(key)\n",
        "      print(\"conf: \", pred_data[0][pred_index])\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gIuL7AUR5Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "7262056a-f1b6-413a-ee88-e5d53a41fa23"
      },
      "source": [
        "predict_on_random_test_data()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Story ============================\n",
            "\n",
            "mary picked up the apple there . mary moved to the kitchen . sandra went to the office . mary travelled to the garden .\n",
            "\n",
            "====================== Question ============================\n",
            "\n",
            "is mary in the garden ?\n",
            "\n",
            "==================== Answer ==============================\n",
            "\n",
            "yes\n",
            "conf:  0.8302403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwaGhYB8SBEP",
        "colab_type": "text"
      },
      "source": [
        "### Predict on manually created data\n",
        "\n",
        "Remember we will be bound to only use those words which are already available in tokenizer vocab. i.e. On which words model is trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9M1Hrd5JzoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_on_created_data(my_story, my_que):\n",
        "  my_story = my_story.split()\n",
        "  my_que = my_que.split()\n",
        "  \n",
        "  print(\"====================== Story ============================\\n\")\n",
        "  print(\" \".join(my_story))\n",
        "  print(\"\\n====================== Question ============================\\n\")\n",
        "  print(\" \".join(my_que))\n",
        "  print(\"\\n==================== Answer ==============================\\n\")\n",
        "  \n",
        "  mydata = [(my_story, my_que, \"yes\")]\n",
        "  my_story, my_que, my_ans = vectorize_stories(mydata)\n",
        "\n",
        "  pred_data = model.predict(([my_story, my_que]))\n",
        "  pred_index = np.argmax(pred_data[0])\n",
        "  for key, val in tokenizer.word_index.items():\n",
        "    if val == pred_index:\n",
        "      print(key)\n",
        "  print(\"conf: \", pred_data[0][pred_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XPA4EPjS71e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "989d58ab-dc1c-418f-9dcc-e9cb39e582a4"
      },
      "source": [
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "\n",
        "my_que = \"Is the football in the garden ?\"\n",
        "\n",
        "predict_on_created_data(my_story, my_que)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Story ============================\n",
            "\n",
            "John left the kitchen . Sandra dropped the football in the garden .\n",
            "\n",
            "====================== Question ============================\n",
            "\n",
            "Is the football in the garden ?\n",
            "\n",
            "==================== Answer ==============================\n",
            "\n",
            "yes\n",
            "conf:  0.94340765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccxSW6NRJdRj",
        "colab_type": "text"
      },
      "source": [
        "###We can load the better weights from already trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcWVVN_cJUHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"chatbot_10.h5\") "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}